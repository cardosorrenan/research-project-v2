{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f7fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "DB_ALIASES = {\n",
    "    \"AFDB\": \"../mit-bih-atrial-fibrillation-database-1.0.0/files\",\n",
    "    \"LTAFDB\": \"../long-term-af-database-1.0.0/files\",\n",
    "    \"NSRDB\": \"../mit-bih-normal-sinus-rhythm-database-1.0.0/files\",\n",
    "}\n",
    "\n",
    "directory = \"./segments_bins\"\n",
    "\n",
    "\n",
    "def clean_annotation(annotation):\n",
    "    sample, aux_note = annotation.sample, annotation.aux_note\n",
    "    non_empty_indices = [i for i, note in enumerate(aux_note) if note != \"\"]\n",
    "    clean_aux_note = [aux_note[i] for i in non_empty_indices]\n",
    "    clean_sample = [sample[i] for i in non_empty_indices]\n",
    "    return clean_sample, clean_aux_note\n",
    "\n",
    "\n",
    "def get_ranges_afib(record_path: str, signal_len: int) -> List[List[int]]:\n",
    "    annotation = wfdb.rdann(record_path, \"atr\")\n",
    "    sample, aux_note = clean_annotation(annotation)\n",
    "    ranges_interest = []\n",
    "    for i, label in enumerate(aux_note):\n",
    "        if label == \"(AFIB\":\n",
    "            afib_start = sample[i]\n",
    "            last_notation = len(sample) == (i + 1)\n",
    "            afib_end = signal_len if last_notation else sample[i + 1] - 1\n",
    "            ranges_interest.append([afib_start, afib_end])\n",
    "    return ranges_interest\n",
    "\n",
    "\n",
    "def cut_array(array_rri: List[int], segment_len: int) -> np.ndarray:\n",
    "    num_segments = len(array_rri) // segment_len\n",
    "\n",
    "    if num_segments <= 0:\n",
    "        return np.empty((0, 0))\n",
    "\n",
    "    segments = np.array(\n",
    "        [\n",
    "            array_rri[i : i + segment_len]\n",
    "            for i in range(0, num_segments * segment_len, segment_len)\n",
    "        ]\n",
    "    )\n",
    "    return segments\n",
    "\n",
    "\n",
    "def get_random_samples_by_label(\n",
    "    base: np.ndarray,\n",
    "    label: int,\n",
    "    n_samples: Optional[int] = 0,\n",
    ") -> np.ndarray:\n",
    "    samples = base[base[:, -1] == label]\n",
    "\n",
    "    if n_samples:\n",
    "        indexes = np.random.choice(samples.shape[0], n_samples, replace=False)\n",
    "        return samples[indexes]\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def get_random_samples(base: np.ndarray, qtd_segments: int) -> np.ndarray:\n",
    "    qtd_segments = int(qtd_segments / 2)\n",
    "    negatives = get_random_samples_by_label(base=base, label=0, n_samples=qtd_segments)\n",
    "    positives = get_random_samples_by_label(base=base, label=1, n_samples=qtd_segments)\n",
    "    base_ready = np.vstack((positives, negatives))\n",
    "    return base_ready\n",
    "\n",
    "\n",
    "def get_record_ids(db_alias: str) -> List[str]:\n",
    "    with open(f\"{DB_ALIASES[db_alias]}/RECORDS\") as f:\n",
    "        lines = f.readlines()\n",
    "        record_ids = [line.strip() for line in lines]\n",
    "\n",
    "    if db_alias == \"AFDB\":\n",
    "        record_ids.remove(\"00735\")\n",
    "        record_ids.remove(\"03665\")\n",
    "\n",
    "    return record_ids\n",
    "\n",
    "\n",
    "def extract_segments_bins(params) -> np.ndarray:\n",
    "    segment_size = params.get(\"segment_size\")\n",
    "    m_bins = params.get(\"m_bins\")\n",
    "    range_hist = params.get(\"range_hist\")\n",
    "    qtd_segments = params.get(\"qtd_segments\")\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    filename = f\"mb{m_bins}_ss{segment_size}_rh{range_hist[0]}-{range_hist[1]}.npy\"\n",
    "\n",
    "    path = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        segment_bins = np.load(path)\n",
    "        return get_random_samples(segment_bins, qtd_segments)\n",
    "\n",
    "    base = np.empty((0, m_bins + 1))\n",
    "\n",
    "    for db_alias in DB_ALIASES.keys():\n",
    "        label = 0 if db_alias == \"NSRDB\" else 1\n",
    "        extension_signal = \"atr\" if db_alias == \"NSRDB\" else \"qrs\"\n",
    "\n",
    "        record_ids = get_record_ids(db_alias)\n",
    "\n",
    "        for record_id in tqdm(record_ids):\n",
    "            record_path = os.path.join(DB_ALIASES[db_alias], record_id)\n",
    "\n",
    "            _, ecg_metadata = wfdb.rdsamp(record_path)\n",
    "            signal_len = ecg_metadata[\"sig_len\"]\n",
    "\n",
    "            extract_intervals = (\n",
    "                get_ranges_afib(record_path, signal_len)\n",
    "                if db_alias in [\"AFDB\", \"LTAFDB\"]\n",
    "                else [[0, signal_len - 1]]\n",
    "            )\n",
    "\n",
    "            for start_index, end_index in extract_intervals:\n",
    "                print(record_path, start_index, end_index, extension_signal)\n",
    "                ann = wfdb.rdann(\n",
    "                    record_path,\n",
    "                    sampfrom=start_index,\n",
    "                    sampto=end_index,\n",
    "                    extension=extension_signal,\n",
    "                )\n",
    "\n",
    "                ann_ms = (ann.sample / ann.fs) * 1000\n",
    "\n",
    "                rr_interval = wfdb.processing.calc_rr(ann_ms, fs=ann.fs)\n",
    "\n",
    "                segments = cut_array(rr_interval, segment_size)\n",
    "\n",
    "                for segment in segments:\n",
    "                    hist, _ = np.histogram(a=segment, range=range_hist, bins=m_bins)\n",
    "                    x = hist\n",
    "                    y = label\n",
    "                    row = np.append(x, y)\n",
    "                    row = row.reshape((1, row.shape[0]))\n",
    "                    base = np.vstack((base, row))\n",
    "\n",
    "    num_rows = base.shape[0]\n",
    "    permutation = np.random.permutation(num_rows)\n",
    "    shuffled_base = base[permutation].copy()\n",
    "\n",
    "    np.save(path, shuffled_base)\n",
    "\n",
    "    return get_random_samples(shuffled_base, qtd_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa568b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../mit-bih-atrial-fibrillation-database-1.0.0/files/04015 102584 119603 ('qrs',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"tuple\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mm_bins\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m40\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mqtd_segments\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1000\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msegment_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m50\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrange_hist\u001b[39m\u001b[39m\"\u001b[39m: (\u001b[39m0\u001b[39m, \u001b[39m2500\u001b[39m),\n\u001b[1;32m      6\u001b[0m } \n\u001b[0;32m----> 7\u001b[0m base \u001b[39m=\u001b[39m extract_segments_bins(params)\n",
      "Cell \u001b[0;32mIn[7], line 129\u001b[0m, in \u001b[0;36mextract_segments_bins\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mfor\u001b[39;00m start_index, end_index \u001b[39min\u001b[39;00m extract_intervals:\n\u001b[1;32m    128\u001b[0m     \u001b[39mprint\u001b[39m(record_path, start_index, end_index, extension_signal)\n\u001b[0;32m--> 129\u001b[0m     ann \u001b[39m=\u001b[39m wfdb\u001b[39m.\u001b[39;49mrdann(\n\u001b[1;32m    130\u001b[0m         record_path,\n\u001b[1;32m    131\u001b[0m         sampfrom\u001b[39m=\u001b[39;49mstart_index,\n\u001b[1;32m    132\u001b[0m         sampto\u001b[39m=\u001b[39;49mend_index,\n\u001b[1;32m    133\u001b[0m         extension\u001b[39m=\u001b[39;49mextension_signal\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     ann_ms \u001b[39m=\u001b[39m (ann\u001b[39m.\u001b[39msample \u001b[39m/\u001b[39m ann\u001b[39m.\u001b[39mfs) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m    138\u001b[0m     rr_interval \u001b[39m=\u001b[39m wfdb\u001b[39m.\u001b[39mprocessing\u001b[39m.\u001b[39mcalc_rr(ann_ms, fs\u001b[39m=\u001b[39mann\u001b[39m.\u001b[39mfs)\n",
      "File \u001b[0;32m~/Área de Trabalho/research-project-2/venv/lib/python3.10/site-packages/wfdb/io/annotation.py:1950\u001b[0m, in \u001b[0;36mrdann\u001b[0;34m(record_name, extension, sampfrom, sampto, shift_samps, pn_dir, return_label_elements, summarize_labels)\u001b[0m\n\u001b[1;32m   1945\u001b[0m return_label_elements \u001b[39m=\u001b[39m check_read_inputs(\n\u001b[1;32m   1946\u001b[0m     sampfrom, sampto, return_label_elements\n\u001b[1;32m   1947\u001b[0m )\n\u001b[1;32m   1949\u001b[0m \u001b[39m# Read the file in byte pairs\u001b[39;00m\n\u001b[0;32m-> 1950\u001b[0m filebytes \u001b[39m=\u001b[39m load_byte_pairs(record_name, extension, pn_dir)\n\u001b[1;32m   1952\u001b[0m \u001b[39m# Get WFDB annotation fields from the file bytes\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m (sample, label_store, subtype, chan, num, aux_note) \u001b[39m=\u001b[39m proc_ann_bytes(\n\u001b[1;32m   1954\u001b[0m     filebytes, sampto\n\u001b[1;32m   1955\u001b[0m )\n",
      "File \u001b[0;32m~/Área de Trabalho/research-project-2/venv/lib/python3.10/site-packages/wfdb/io/annotation.py:2091\u001b[0m, in \u001b[0;36mload_byte_pairs\u001b[0;34m(record_name, extension, pn_dir)\u001b[0m\n\u001b[1;32m   2089\u001b[0m \u001b[39m# local file\u001b[39;00m\n\u001b[1;32m   2090\u001b[0m \u001b[39mif\u001b[39;00m pn_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2091\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(record_name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m extension, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m   2092\u001b[0m         filebytes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfromfile(f, \u001b[39m\"\u001b[39m\u001b[39m<u1\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreshape([\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m])\n\u001b[1;32m   2093\u001b[0m \u001b[39m# PhysioNet file\u001b[39;00m\n\u001b[1;32m   2094\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"tuple\") to str"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"m_bins\": 40,\n",
    "    \"qtd_segments\": 1000,\n",
    "    \"segment_size\": 50,\n",
    "    \"range_hist\": (0, 2500),\n",
    "}\n",
    "base = extract_segments_bins(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cff8109849478b80d849fa9b19485249a5dc5257b812874e006f7dba7d5866b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
